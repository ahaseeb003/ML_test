# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18aQR9YvkzJynDSGoxy7A6TmVLEZwyeKG
"""

import pandas as pd
import numpy as np

# --- 1. Create Data for Supervised/Unsupervised Learning ---
# Scenario: Users with 'Age' and 'Salary'.
# 'Purchased' is the label (0 = No, 1 = Yes).
data = {
    'Age': [22, 25, 47, 52, 46, 56, 21, 23, 55, 60, 20, 30, 40, 45, 50, 28, 33],
    'Salary': [20000, 22000, 80000, 85000, 82000, 90000, 18000, 25000, 110000, 115000, 19000, 50000, 60000, 95000, 100000, 29000, 52000],
    'Purchased': [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0] # 0 = No, 1 = Yes
}
df_users = pd.DataFrame(data)
df_users.to_csv('users.csv', index=False)
print("✅ Created 'users.csv' for Supervised/Unsupervised learning.")

# --- 2. Create Data for Reinforcement Learning ---
# Scenario: A grid maze where 0=Empty, 1=Wall, 2=Start, 3=Goal
# The agent must read this CSV and learn to find the path.
maze_grid = [
    [2, 0, 0, 0, 0],
    [1, 1, 1, 1, 0],
    [0, 0, 0, 1, 0],
    [0, 1, 0, 1, 0],
    [0, 0, 0, 0, 3]
]
df_maze = pd.DataFrame(maze_grid)
df_maze.to_csv('maze.csv', index=False, header=False)
print("✅ Created 'maze.csv' for Reinforcement Learning.")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier

# 1. Load Data
df = pd.read_csv('users.csv')
X = df[['Age', 'Salary']].values
y = df['Purchased'].values

# 2. Train Model (We GIVE it the answers 'y')
model = RandomForestClassifier(n_estimators=10, random_state=42)
model.fit(X, y)

# 3. Visualization
plt.figure(figsize=(8, 6))

# Create a background mesh to show the "Decision Boundary"
x_min, x_max = X[:, 0].min() - 5, X[:, 0].max() + 5
y_min, y_max = X[:, 1].min() - 5000, X[:, 1].max() + 5000
xx, yy = np.meshgrid(np.arange(x_min, x_max, 1), np.arange(y_min, y_max, 1000))
Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

# Plot
plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm') # Background regions
scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='k', s=100)
plt.xlabel('Age')
plt.ylabel('Salary')
plt.title('SUPERVISED: Random Forest\n(Background color = Model Prediction)')
plt.legend(handles=scatter.legend_elements()[0], labels=['Did Not Buy', 'Bought'])
plt.grid(True, alpha=0.3)
plt.show()

print("Analysis: The model learned that high Age/Salary usually means 'Bought' (Red area).")

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# 1. Load Data
df = pd.read_csv('users.csv')
X = df[['Age', 'Salary']].values
# NOTE: We drop 'Purchased'. The model works blindly!

# 2. Train Model (No answers given)
# We ask it to find 2 groups (clusters)
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
kmeans.fit(X)

# 3. Visualization
plt.figure(figsize=(8, 6))

# Plot the points colored by the cluster the MACHINE found
plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis', edgecolors='k', s=100)

# Plot the "Centroids" (The mathematical center of the group)
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='red', s=300, marker='X', label='Centroids')

plt.xlabel('Age')
plt.ylabel('Salary')
plt.title('UNSUPERVISED: K-Means Clustering\n(Colors = Groups found by AI)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

print("Analysis: The AI found 2 distinct groups (Purple vs Yellow) purely based on Salary/Age differences.")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load Environment from CSV
maze_df = pd.read_csv('maze.csv', header=None)
maze = maze_df.values
rows, cols = maze.shape

# 2. Q-Learning Setup
# Q-Table stores the "value" of every action in every cell
q_table = np.zeros((rows, cols, 4)) # 4 Actions: Up, Down, Left, Right
actions = [(-1, 0), (1, 0), (0, -1), (0, 1)] # Directions

# Parameters
epsilon = 0.9  # How much we explore randomly
gamma = 0.9    # Importance of future rewards
learning_rate = 0.9

# 3. Training Loop (The "Game")
print("Training Agent on CSV Maze... (This takes a few seconds)")
for episode in range(1000): # Play the game 1000 times
    # Find start position
    start_pos = np.argwhere(maze == 2)[0]
    state = start_pos

    while True:
        r, c = state

        # Check if Goal (3) reached
        if maze[r, c] == 3:
            break

        # Choose Action (Explore vs Exploit)
        if np.random.rand() < epsilon:
            action_idx = np.random.randint(4) # Random move
        else:
            action_idx = np.argmax(q_table[r, c]) # Best known move

        dr, dc = actions[action_idx]
        new_r, new_c = r + dr, c + dc

        # Check boundaries and walls (1)
        if 0 <= new_r < rows and 0 <= new_c < cols and maze[new_r, new_c] != 1:
            # Reward: 10 for Goal, -1 for moving (to encourage speed)
            reward = 10 if maze[new_r, new_c] == 3 else -1

            # Update Q-Table (The "Brain")
            old_value = q_table[r, c, action_idx]
            next_max = np.max(q_table[new_r, new_c])
            q_table[r, c, action_idx] = old_value + learning_rate * (reward + gamma * next_max - old_value)

            state = [new_r, new_c]
        else:
            # Hit a wall or edge, slight penalty, stay in place
            q_table[r, c, action_idx] -= 10

    # Reduce exploration over time
    if epsilon > 0.1: epsilon -= 0.001

# 4. Visualization of the Best Path
plt.figure(figsize=(6, 6))
sns.heatmap(maze, cmap="Pastel1", cbar=False, linewidths=1, linecolor='black')

# Draw the path based on what the agent learned
current = np.argwhere(maze == 2)[0]
path_x, path_y = [current[1]+0.5], [current[0]+0.5]

steps = 0
while maze[current[0], current[1]] != 3 and steps < 20:
    # Agent chooses best action from Q-table
    action_idx = np.argmax(q_table[current[0], current[1]])
    dr, dc = actions[action_idx]
    current = [current[0] + dr, current[1] + dc]
    path_x.append(current[1]+0.5)
    path_y.append(current[0]+0.5)
    steps += 1

plt.plot(path_x, path_y, marker='o', color='red', linewidth=3, markersize=10, label='Learned Path')
plt.title('REINFORCEMENT: Q-Learning Agent\n(Navigating the CSV Maze)')
plt.legend()
plt.gca().invert_yaxis()
plt.show()

